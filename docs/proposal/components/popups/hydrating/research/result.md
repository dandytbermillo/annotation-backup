Summary of Findings
The primary source of hydration latency is the series of network requests performed for each popup overlay during restoration. After loading the saved overlay layout from storage (a single API call), the code sequentially fetches data for each popup’s folder: first retrieving the folder’s metadata, then walking up its ancestor chain (one fetch per ancestor until a color is found), and finally fetching the folder’s children list. These per-popup requests dominate hydration time. They are initiated in parallel across multiple popups (using an async loop), but within each popup the calls occur back-to-back. This means each overlay panel’s content is gated by several round-trip calls, which can significantly slow down full hydration – especially if a folder has no color and triggers multiple ancestor fetches.
Meanwhile, the application’s layout lock (isWorkspaceLayoutLoading) is held only during the initial layout restoration and then released early – before each popup’s content is fully fetched. The code sets this lock true when starting to hydrate the layout and sets it false immediately after applying the base layout (i.e. after rendering the popup windows with placeholders). In practice, this means the UI becomes interactive as soon as the overlay windows are in place, while the popups continue loading their contents in the background. Releasing the lock at that point does not compromise correctness: each popup panel manages its own isLoading state and shows a “Loading…” indicator for its content until hydration finishes. This decoupling of layout application from popup decoration is already implemented, allowing users to move or interact with the overlay frames quickly, even if the panel contents are still streaming in.
Bottleneck Details
Sequential Fetches Per Popup: Each overlay popup goes through a fixed sequence of network requests during hydration. In AnnotationApp.applyOverlayLayout, the code iterates over all restored popups and for each one it performs: (1) a GET request to /api/items/{folderId} to load the folder’s details (name, color, etc.), (2) if the folder has no color, a loop of up to 10 requests to fetch ancestor folders one-by-one until a color is found (this is a linear walk up the hierarchy), and (3) a GET request to /api/items?parentId={folderId} to retrieve the folder’s child items (for the overlay’s list view). Only after all these calls resolve does the popup’s state get updated with the folder’s true name/color and children list. The ancestor chain fetches are clearly a bottleneck – in the worst case (no color on any ancestor within 10 levels) the code will make 1 (folder) + 10 (ancestors) + 1 (children) = 12 sequential requests for a single popup before it is fully hydrated.
Parallel vs. Blocking Behavior: It’s worth noting that the hydration loop launches an asynchronous fetch for each popup without awaiting each in turn. This means popups load concurrently up to a point. For example, if there are 3 popups open, the folder metadata requests for all three are fired off roughly in parallel. However, within each popup’s task the steps are sequential, so each panel cannot finish loading until its own series of calls completes. There is no Promise.all to await all popups’ data, and the code doesn’t move to a next step globally – instead, each overlay updates itself individually when ready. In terms of blocking the UI, these network calls are not blocking the rendering thread (they’re async), and as mentioned the global layout lock isn’t held during this phase. The main user-visible delay is that each overlay panel shows a “Loading…” state until its data arrives. If network latency is high or if many sequential calls are needed (e.g. a deep ancestor chain), the panel remains in that loading state longer. This per-panel delay is the principal contributor to the overall feeling of slowness during hydration.
Layout Lock Timing: The isWorkspaceLayoutLoading flag (used to lock the workspace UI) is only active during initial layout load. As seen in the code, the app sets the lock true before fetching the saved layout and turns it off immediately after calling applyOverlayLayout (which inserts the overlay popups into state). In other words, the lock covers the period of retrieving the layout JSON from the server and rendering the popup containers, but it does not extend through the per-popup data fetching. The PopupOverlay component respects this lock via its isLocked prop – when true, it prevents interactions (grabs, resizes, etc.) and even displays a semi-opaque “hydrating” banner or wait cursor over the canvas. By line 1513 of annotation-app.tsx, that lock is cleared, so as soon as the empty popup windows are on screen, the user can start interacting (the overlays can be dragged, closed, etc.). Each popup still has its popup.isLoading flag true (so its content area is disabled with a Loading message), but the surrounding workspace is unlocked. This design indicates the developers have already moved the lock release as early as safely possible – the base layout hydration is separated from content loading. As a result, the remaining latency is almost entirely due to the network fetches for popup content, not any artificial blocking by the app after the initial layout is set.
Potential Improvements
Parallelize Fetches Within Each Popup: The current implementation fetches a popup’s folder info, then serially fetches ancestors, then children. These could be parallelized or restructured to cut down wait time. For example, once the folder’s metadata is obtained, the app could initiate the children list request in parallel with the ancestor color resolution. The children endpoint (/api/items?parentId=) does not depend on knowing the ancestor colors, so it could be fetched as soon as the folder ID is known (after the first call) rather than waiting for the color loop to finish. Doing this would overlap the network I/O and likely reduce total time per popup. Pros: Faster hydration for each popup (children can load while we resolve color). The user might see the list of items appear sooner (even if the folder color/breadcrumb updates a moment later). Cons: Added complexity – the code must manage two concurrent results and then combine them. We’d need to be careful to only mark isLoading=false when both the children and any needed color info are ready, and handle partial failures (e.g. folder loaded but children failed or vice versa). Nonetheless, this parallelization could improve perceived performance by not doing all calls in strict sequence.
Reduce Ancestor Chain Requests (Color Fetch): The ancestor traversal for folder color is a clear multi-call sequence that could be optimized. One idea is to batch or cache these ancestor lookups. For instance, if multiple popups are being hydrated and share some ancestors, the code could reuse the result of a parent fetch instead of hitting the same endpoint twice. A simple caching mechanism (in-memory during hydration) mapping folder IDs to their color could prevent redundant requests. Another idea is a more efficient API: e.g., an endpoint that returns a folder’s entire ancestor chain or inherited color in one go. If the backend could provide the nearest ancestor with a color as part of the folder metadata, it would eliminate the need for the loop entirely. Pros: Fewer network round-trips – in the best case, determining the color could be a single request or even zero additional requests if cached. This would especially help deep hierarchies. Cons: Implementing a new API or caching logic adds development overhead. Caching must be invalidated or scoped carefully (e.g. only within the hydration session) to avoid using stale data. Also, if ancestor color fetching is not a frequent occurrence (e.g. if most folders have their own color), the performance gain might be limited. Still, given the potential worst-case (10 extra calls per popup), addressing this bottleneck is worthwhile.
Batching Children Requests: If many popups are open at once, the app ends up firing multiple /api/items?parentId=... calls for each folder’s children. Depending on server capabilities, these could possibly be batched into one request (for example, an API that accepts multiple parentIds and returns a combined result). Batching would reduce HTTP overhead when loading many panels simultaneously. However, this optimization might have diminishing returns unless users commonly have a large number of overlays open. Pros: Lower total number of HTTP requests – better network efficiency when hydrating lots of popups at once. Cons: Requires backend changes or an aggregator call; plus, the response handling becomes more complex (sorting out which children belong to which popup). Given that popups are usually opened on-demand, this may be a micro-optimization, but it’s something to consider if profiling shows a network bottleneck when restoring very overlay-heavy workspaces.
Leverage Saved Data / Caching: The app already stores some popup info in the saved layout (e.g. folderName and a cached folderColor in the overlay descriptor). Ensuring we utilize these cached values can shorten what needs to be fetched. For example, if folderName and folderColor were saved and the folder’s name/color haven’t changed, the UI could use them immediately without waiting for the /api/items response. Currently the code does use the cached color as a fallback until the real data arrives, and it keeps the saved folderName as an initial label. This is good – it means the popup title is populated and colored (if previously known) even while loading. We should continue to expand such caching where possible (perhaps caching child lists or at least their count if that was known) to give the user some immediate feedback. Pros: Using cached info can make the UI feel more instant (less “blank” content initially). If we had, say, cached child item IDs from last session, we might even optimistically display them (stale-while-refresh approach). Cons: Cached data can be outdated – for example, items might have been added/removed, so any optimistic display would need to reconcile with the server result. This is more of a UX tweak than a true performance gain, but it can improve perceived latency by showing something while waiting.
Early Unlock Validation: The current approach of unlocking the workspace right after base layout is applied is already a positive pattern. We should continue with this early unlock, and we might double-check if there are any opportunities to unlock even a bit earlier without risking race conditions. For instance, one could imagine dropping the lock right before setting the state (setOverlayPopups) if the UI can handle popups appearing dynamically. However, in practice the lock duration is so brief (just the span of fetching the layout JSON and calling applyOverlayLayout) that there is little to gain by any earlier unlock. Any attempt to allow user actions before the popups state is set could lead to inconsistent behavior (e.g. the user clicking to open a new overlay while the old layout is still coming in). Thus, the current timing (unlock immediately after setOverlayPopups) seems optimal. Pros: (of the current pattern) Users aren’t stuck waiting for all panels to finish loading – they can rearrange or work in parallel, improving responsiveness. Cons: If a user interacts with a popup that’s mid-hydration (e.g. tries to scroll or rename it while its content is not yet loaded), there’s a slight chance of odd behavior. In our case, interactions inside a popup are naturally limited until children load, and the code already disables certain actions when popup.isLoading (the content area just says “Loading...”). So far no correctness issues have been observed with early unlocking, confirming it’s a safe approach.
Next Steps
Profile and Measure: Start by instrumenting or profiling the hydration flow to quantify the delays. Measure how long each phase takes – the layout fetch, the per-popup folder fetch, ancestor resolution, and children fetch. This will highlight which sub-step is the biggest offender (likely the network calls, as suspected). For example, using console timing or performance marks around the hydration loop could help confirm that, say, ancestor fetch loops are adding X ms on average. Having these numbers will guide which optimization yields the most benefit.
Implement Parallel Fetching: Modify the hydration logic to perform non-dependent requests in parallel. Concretely, we can refactor the forEach loop into something like: for each popup, do the folder fetch first (we need the base data), then kick off the children fetch at the same time as any ancestor color fetch if needed. This could involve using Promise.all for the children and ancestor promises. Test this change with various scenarios (popups with color vs no color, different network speeds) to ensure that all data still arrives and populates correctly. Verify that isLoading is only cleared at the right time (after both promises finish) and that the UI shows no regressions.
Optimize Ancestor Color Retrieval: If parallelization isn’t enough or in addition to it, consider implementing a caching mechanism for folder colors during hydration. A simple approach would be to keep a dictionary of folderId -> color that persists for the duration of the hydration. Before fetching an ancestor, check this cache; after fetching, store the result. This ensures we don’t refetch the same folder’s data twice in one hydration session. Test with a deep nested structure (and multiple popups in the same branch) to confirm that one ancestor is indeed fetched only once. Alternatively, explore a server-side solution: perhaps extend the /api/items/{id} response to include an ancestorColor field or the immediate parent’s color, so that typically one additional call (at most) is needed instead of potentially 10. Any server-side changes would need coordination with the backend team but could drastically cut down latency for edge cases.
Batch or Throttle Requests: If profiling shows that the network is getting hammered when many popups open at once, you might batch some requests or throttle them. For instance, opening 10 overlays could spawn 10 folder fetches and 10 child fetches nearly simultaneously. Modern browsers handle this fine, but if the server starts queueing or if there are rate limits, we may need to stagger some calls. Batching multiple child fetches into one request (if supported by the API) can be explored. This step is optional and should be driven by real-world data – if users rarely open huge numbers of popups at once, the complexity might not be justified.
Validate UI/UX with Early Unlock: Since we plan to keep the early release of the layout lock, we should run through user flows to ensure no correctness issues. Test interacting with the workspace immediately on load: try moving a popup while it’s still loading children, closing a popup quickly before it finished hydrating, or creating a new popup during the hydration of existing ones. The goal is to catch any race conditions. Thus far, the design (with each popup independently loading and a global layoutLoadedRef to gate saves) appears solid. After any changes to the loading sequence, repeat these tests to confirm the early unlock remains safe.
By addressing the network request pattern and possibly reducing the number of sequential calls, we expect to see faster hydration of popup overlays. Each of the above improvements (parallel fetching, caching ancestor data, etc.) should trim down latency without altering the core functionality. Combining these optimizations with thorough testing will ensure that we improve performance while maintaining correct and predictable behavior of the application.